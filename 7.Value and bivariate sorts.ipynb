{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value and bivariate sorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter extends univariate portfolio analysis to bivariate sorts which means that we assign stocks to portfolios based on two characteristics. Bivariate sorts are regularly used in the academic asset pricing literature. Yet, some scholars also use sorts with three grouping variables. Conceptually, portfolio sorts are easily applicable in higher dimensions.\n",
    "\n",
    "We form portfolios on firm size and the book-to-market ratio. To calculate book-to-market ratios, accounting data is required which necessitates additional steps during portfolio formation. In the end, we demonstrate how to form portfolios on two sorting variables using so-called independent and dependent portfolio sorts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the necessary data from our `SQLite`-database introduced in our chapter on *\"Accessing & managing financial data\"*. We conduct portfolio sorts based on the CRSP sample but keep only the necessary columns in our memory. We use the same data sources for firm size as in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "tidy_finance = sqlite3.connect(\"D:/Tidy/tidyfinance.sqlite\")\n",
    "crsp_monthly = pd.read_sql_query(\"SELECT * from crsp_monthly\", tidy_finance)\n",
    "factors_ff_monthly = pd.read_sql_query(\"SELECT * from factors_ff_monthly\", tidy_finance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_monthly=pd.merge(crsp_monthly,factors_ff_monthly,left_on='month',right_on='month')[['permno','gvkey', 'month', 'industry', 'ret_excess', 'mkt_excess','mktcap', 'mktcap_lag', 'exchange']]\n",
    "crsp_monthly['month']=pd.to_datetime(crsp_monthly['month'])\n",
    "crsp_monthly['permno']=crsp_monthly['permno'].astype(int)\n",
    "crsp_monthly=crsp_monthly.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we utilize accounting data. The most common source of accounting data is *Compustat*. We only need book equity data in this application, which we select from our database. Additionally, we convert the variable `datadate` to its monthly value, as we only consider monthly returns here and do not need to account for the exact date. To achieve this, we use the function `pd.to_datetime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compustat = pd.read_sql_query(\"SELECT * from compustat\", tidy_finance)\n",
    "be = compustat[['gvkey', 'datadate', 'be']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "be['month']=pd.to_datetime(be['datadate']) + timedelta(days=1) - pd.DateOffset(months=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book-to-market ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fundamental problem in handling accounting data is the *look-ahead bias* - we must not include data in forming a portfolio that is not public knowledge at the time. Of course, researchers have more information when looking into the past than agents had at that moment. However, abnormal excess returns from a trading strategy should not rely on an information advantage because the differential cannot be the result of informed agents' trades. Hence, we have to lag accounting information.\n",
    "\n",
    "We continue to lag market capitalization and firm size by one month. Then, we compute the book-to-market ratio, which relates a firm's book equity to its market equity. Firms with high (low) book-to-market are called value (growth) firms. After matching the accounting and market equity information from the same month, we lag book-to-market by six months. This is a sufficiently conservative approach because accounting information is usually released well before six months pass. However, in the asset pricing literature, even longer lags are used as well.^[The definition of a time lag is another choice a researcher has to make, similar to breakpoint choices as we describe in the section on p-hacking.]\n",
    "\n",
    "Having both variables, i.e., firm size lagged by one month and book-to-market lagged by six months, we merge these sorting variables to our returns using the `sorting_date`-column created for this purpose. The final step in our data preparation deals with differences in the frequency of our variables. Returns and firm size are recorded monthly. Yet the accounting information is only released on an annual basis. Hence, we only match book-to-market to one month per year and have eleven empty observations. To solve this frequency issue, we carry the latest book-to-market ratio of each firm to the subsequent months, i.e., we fill the missing observations with the most current report. This is done via the `fillna()`-function after sorting by date and firm (which we identify by permno and gvkey) and on a firm basis (which we do by `groupby()` as usual). As the last step, we remove all rows with missing entries because the returns cannot be matched to any annual report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "me=crsp_monthly.assign(sorting_date = crsp_monthly.month + pd.DateOffset(months=1))[['permno', 'sorting_date','mktcap']].rename(columns={'mktcap':'me'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm=be.merge(crsp_monthly[['month', 'permno', 'gvkey', 'mktcap']],left_on=[\"gvkey\", \"month\"],right_on=[\"gvkey\", \"month\"],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm=bm.assign(bm=bm.be/bm.mktcap,sorting_date = bm.month + pd.DateOffset(months=6))[['permno', 'gvkey', 'sorting_date', 'bm']].sort_values(['permno', 'gvkey', 'sorting_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=crsp_monthly.merge(bm, left_on=[\"permno\", \"gvkey\", \"month\"],right_on=[\"permno\", \"gvkey\", 'sorting_date'],how='left').merge(me, left_on=[\"permno\",  \"month\"],right_on=[\"permno\",'sorting_date'],how='left')[['permno', 'gvkey', 'month', 'ret_excess', 'mktcap_lag','me', 'bm', 'exchange']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=data_for_sorts.sort_values(['permno', 'gvkey', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=data_for_sorts.assign(bm=data_for_sorts.groupby(['permno', 'gvkey']).bm.fillna(method='ffill')).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step of preparation for the portfolio sorts is the computation of breakpoints. We continue to use the same function allowing for the specification of exchanges to use for the breakpoints. Additionally, we reintroduce the argument `var` into the function for defining different sorting variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket(row,var,groups):\n",
    "    if groups == 5:\n",
    "        if 0<=row[var]<=row['20%']:\n",
    "            value = 1\n",
    "        elif row[var]<=row['40%']:\n",
    "            value=2\n",
    "        elif row[var]<=row['60%']:\n",
    "            value=3\n",
    "        elif row[var]<=row['80%']:\n",
    "            value=4\n",
    "        elif row[var]>row['80%']:\n",
    "            value=5\n",
    "        else:\n",
    "            value=''\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def assign_portfolio(df,var,groups,exchange):\n",
    "    nyse = df.loc[df['exchange'].isin(exchange)].groupby([\"month\"])[var].describe(percentiles=np.linspace(0,1,groups+1)[1:-1]).reset_index()\n",
    "    if groups % 2==1:\n",
    "        nyse=nyse.iloc[:,[0]+list(range(5,5+groups))].merge(df, how='inner', left_on=['month'], right_on = ['month'])\n",
    "    else:\n",
    "        nyse=nyse.iloc[:,[0]+list(range(5,5+groups-1))].merge(df, how='inner',left_on=['month'], right_on = ['month'])\n",
    "    nyse['portfolio_{}'.format(var)]=nyse.apply( lambda x:bucket(x,var,groups), axis=1)\n",
    "    nyse=nyse.sort_values(['permno','month'])\n",
    "    return nyse    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these data preparation steps, we present bivariate portfolio sorts on an independent and dependent basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compustat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12252\\2156782146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompustat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'compustat' is not defined"
     ]
    }
   ],
   "source": [
    "del(compustat)\n",
    "del(crsp_monthly)\n",
    "del(bm)\n",
    "del(be)\n",
    "del(me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent sorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bivariate sorts create portfolios within a two-dimensional space spanned by two sorting variables. It is then possible to assess the return impact of either sorting variable by the return differential from a trading strategy that invests in the portfolios at either end of the respective variables spectrum. We create a five-by-five matrix using book-to-market and firm size as sorting variables in our example below. We end up with 25 portfolios. Since we are interested in the *value premium* (i.e., the return differential between high and low book-to-market firms), we go long the five portfolios of the highest book-to-market firms and short the five portfolios of the lowest book-to-market firms. The five portfolios at each end are due to the size splits we employed alongside the book-to-market splits.\n",
    "\n",
    "To implement the independent bivariate portfolio sort, we assign monthly portfolios for each of our sorting variables separately to create the variables `portfolio_bm` and `portfolio_bm`, respectively. Then, these separate portfolios are combined to the final sort stored in `portfolio_combined`. After assigning the portfolios, we compute the average return within each portfolio for each month. Additionally, we keep the book-to-market portfolio as it makes the computation of the value premium easier. The alternative would be to disaggregate the combined portfolio in a separate step. Notice that we weigh the stocks within each portfolio by their market capitalization, i.e., we decide to value-weight our returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=data_for_sorts.merge(assign_portfolio(data_for_sorts,'bm',5,['NYSE'])[['permno','portfolio_bm','month']],left_on=['permno','month'],right_on=['permno','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=data_for_sorts.merge(assign_portfolio(data_for_sorts,'me',5,['NYSE'])[['permno','portfolio_me','month']],left_on=['permno','month'],right_on=['permno','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_portfolios=data_for_sorts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_portfolios['portfolio_combined']=value_portfolios.apply(lambda x:str(int(x['portfolio_bm'])) + '-' + str(int(x['portfolio_me'])),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipped with our monthly portfolio returns, we are ready to compute the value premium. However, we still have to decide how to invest in the five high and the five low book-to-market portfolios. The most common approach is to weigh these portfolios equally, but this is yet another researcher's choice. Then, we compute the return differential between the high and low book-to-market portfolios and show the average value premium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_premium=value_portfolios.groupby(['month','portfolio_combined']).apply(lambda x: pd.Series([np.average(x['ret_excess'], weights=x['mktcap_lag'])], \n",
    "                                                                index=['ret'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_premium['portfolio_bm']=value_premium.portfolio_combined.apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_premium=value_premium.groupby(['month', 'portfolio_bm']).ret.mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3063750693423136"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(value_premium.iloc[: , -1]-value_premium.iloc[: , 0]).mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent sorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, we assigned the portfolios without considering the second variable in the assignment. This protocol is called independent portfolio sorts. The alternative, i.e., dependent sorts, creates portfolios for the second sorting variable within each bucket of the first sorting variable. In our example below, we sort firms into five size buckets, and within each of those buckets, we assign firms to five book-to-market portfolios. Hence, we have monthly breakpoints that are specific to each size group. The decision between independent and dependent portfolio sorts is another choice for the researcher. Notice that dependent sorts ensure an equal amount of stocks within each portfolio.\n",
    "\n",
    "To implement the dependent sorts, we first create the size portfolios by calling `assign_portfolio()` with `var = me`. Then, we group our data again by month and by the size portfolio before assigning the book-to-market portfolio. The rest of the implementation is the same as before. Finally, we compute the value premium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=data_for_sorts.drop(['portfolio_bm','portfolio_me'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=data_for_sorts.merge(assign_portfolio(data_for_sorts,'me',5,['NYSE'])[['permno','portfolio_me','month']],left_on=['permno','month'],right_on=['permno','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse=data_for_sorts.loc[data_for_sorts['exchange'].isin(['NYSE'])].groupby(['month','portfolio_me'])['bm'].describe(percentiles=np.linspace(0,1,5+1)[1:-1]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>portfolio_me</th>\n",
       "      <th>20%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>60%</th>\n",
       "      <th>80%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3.043874</td>\n",
       "      <td>3.086235</td>\n",
       "      <td>3.107416</td>\n",
       "      <td>3.128596</td>\n",
       "      <td>3.170957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.892990</td>\n",
       "      <td>0.892990</td>\n",
       "      <td>0.892990</td>\n",
       "      <td>0.892990</td>\n",
       "      <td>0.892990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1.551437</td>\n",
       "      <td>1.551437</td>\n",
       "      <td>1.551437</td>\n",
       "      <td>1.551437</td>\n",
       "      <td>1.551437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1.095951</td>\n",
       "      <td>1.095951</td>\n",
       "      <td>1.095951</td>\n",
       "      <td>1.095951</td>\n",
       "      <td>1.095951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1.298501</td>\n",
       "      <td>1.612112</td>\n",
       "      <td>1.768917</td>\n",
       "      <td>1.925723</td>\n",
       "      <td>2.239334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467692</td>\n",
       "      <td>0.747937</td>\n",
       "      <td>0.914651</td>\n",
       "      <td>1.106672</td>\n",
       "      <td>1.689066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.332199</td>\n",
       "      <td>0.516728</td>\n",
       "      <td>0.666623</td>\n",
       "      <td>0.777333</td>\n",
       "      <td>1.002481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.228130</td>\n",
       "      <td>0.396968</td>\n",
       "      <td>0.468030</td>\n",
       "      <td>0.537173</td>\n",
       "      <td>0.803560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.154653</td>\n",
       "      <td>0.267289</td>\n",
       "      <td>0.373745</td>\n",
       "      <td>0.487313</td>\n",
       "      <td>0.711881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.208143</td>\n",
       "      <td>0.275927</td>\n",
       "      <td>0.350075</td>\n",
       "      <td>0.615340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3625 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          month  portfolio_me       20%       40%       50%       60%  \\\n",
       "0    1960-08-01             1  3.043874  3.086235  3.107416  3.128596   \n",
       "1    1960-08-01             2  0.892990  0.892990  0.892990  0.892990   \n",
       "2    1960-08-01             3  1.551437  1.551437  1.551437  1.551437   \n",
       "3    1960-08-01             4  1.095951  1.095951  1.095951  1.095951   \n",
       "4    1960-08-01             5  1.298501  1.612112  1.768917  1.925723   \n",
       "...         ...           ...       ...       ...       ...       ...   \n",
       "3620 2020-12-01             1  0.467692  0.747937  0.914651  1.106672   \n",
       "3621 2020-12-01             2  0.332199  0.516728  0.666623  0.777333   \n",
       "3622 2020-12-01             3  0.228130  0.396968  0.468030  0.537173   \n",
       "3623 2020-12-01             4  0.154653  0.267289  0.373745  0.487313   \n",
       "3624 2020-12-01             5  0.101272  0.208143  0.275927  0.350075   \n",
       "\n",
       "           80%  \n",
       "0     3.170957  \n",
       "1     0.892990  \n",
       "2     1.551437  \n",
       "3     1.095951  \n",
       "4     2.239334  \n",
       "...        ...  \n",
       "3620  1.689066  \n",
       "3621  1.002481  \n",
       "3622  0.803560  \n",
       "3623  0.711881  \n",
       "3624  0.615340  \n",
       "\n",
       "[3625 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyse.iloc[:,[0,1]+list(range(6,5+5+1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse=nyse.iloc[:,[0,1]+list(range(6,5+5+1))].merge(data_for_sorts, how='inner',left_on=['month','portfolio_me'], right_on = ['month','portfolio_me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse['portfolio_bm']=nyse.apply( lambda x:bucket(x,'bm',5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_sorts=nyse.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25145431478579017"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_portfolios=data_for_sorts.dropna()\n",
    "value_portfolios['portfolio_combined']=value_portfolios.apply(lambda x:str(int(x['portfolio_bm'])) + '-' + str(int(x['portfolio_me'])),axis = 1)\n",
    "value_premium=value_portfolios.groupby(['month','portfolio_combined']).apply(lambda x: pd.Series([np.average(x['ret_excess'], weights=x['mktcap_lag'])], \n",
    "                                                                index=['ret'])).reset_index()\n",
    "value_premium['portfolio_bm']=value_premium.portfolio_combined.apply(lambda x:x[0])\n",
    "value_premium=value_premium.groupby(['month', 'portfolio_bm']).ret.mean().unstack()\n",
    "(value_premium.iloc[: , -1]-value_premium.iloc[: , 0]).mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value premium from dependent sorts is 3.02 percent per year.\n",
    "\n",
    "Overall, we show how to conduct bivariate portfolio sorts in this chapter. In one case, we sort the portfolios independently of each other. Yet we also discuss how to create dependent portfolio sorts. Along the line of the previous chapter, we see how many choices a researcher has to make to implement portfolio sorts, and bivariate sorts increase the number of choices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "670636528462d7cb6f82d90df507c1e6f4b23efee7fba44815f39cb55d1b33a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
